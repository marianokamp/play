{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/d7/90f34cb0d83a6c5631cf71dfe64cc1054598c843a92b400e55675cc2ac37/pip-18.1-py2.py3-none-any.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.3MB 9.5MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 10.0.1\n",
      "    Uninstalling pip-10.0.1:\n",
      "      Successfully uninstalled pip-10.0.1\n",
      "Successfully installed pip-18.1\n",
      "Requirement already satisfied: pyathena in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.4.2)\n",
      "Requirement already satisfied: tenacity>=4.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyathena) (5.0.2)\n",
      "Requirement already satisfied: botocore>=1.5.52 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyathena) (1.10.84)\n",
      "Requirement already satisfied: boto3>=1.4.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyathena) (1.7.82)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyathena) (0.16.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tenacity>=4.1.0->pyathena) (1.11.0)\n",
      "Requirement already satisfied: docutils>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.5.52->pyathena) (0.14)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.5.52->pyathena) (0.9.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.5.52->pyathena) (2.7.3)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.4.4->pyathena) (0.1.13)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install pyathena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files are retrieved from [here](http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml) and named like this: https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2018-01.csv\n",
    "\n",
    "Those files are stored in S3. https://registry.opendata.aws/nyc-tlc-trip-records-pds/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREEN_RAW_LOCAL  = '~/data/nyc_green/'\n",
    "YELLOW_RAW_LOCAL = '~/data/nyc_yellow/'\n",
    "STAGING_BUCKET = 's3://mkamp-aws-tmp/nyc_tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/data/nyc_yellow/\n",
      "total 8\n",
      "drwxrwxr-x 2 ec2-user ec2-user 4096 Oct 21 14:05 nyc_green\n",
      "drwxrwxr-x 2 ec2-user ec2-user 4096 Oct 21 14:05 nyc_yellow\n",
      "ref:\n",
      "green:\n",
      "yellow:\n",
      "2018-10-21 15:35:32      12322 taxi _zone_lookup.csv\n",
      "CPU times: user 142 ms, sys: 84.2 ms, total: 226 ms\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!echo {YELLOW_RAW_LOCAL}\n",
    "!mkdir -p {GREEN_RAW_LOCAL}\n",
    "!mkdir -p {YELLOW_RAW_LOCAL}\n",
    "!ls -l ~/data/\n",
    "\n",
    "print('ref:')\n",
    "!aws s3 sync 's3://nyc-tlc/misc/' {STAGING_BUCKET}/ref --exclude=\"*\" --include='taxi _zone_lookup.csv' \n",
    "\n",
    "print('green:')\n",
    "!aws s3 sync 's3://nyc-tlc/trip data/' {STAGING_BUCKET}/green --exclude=\"*\" --include='green_tripdata_2016*.csv' --quiet\n",
    "!aws s3 sync 's3://nyc-tlc/trip data/' {STAGING_BUCKET}/green --exclude=\"*\" --include='green_tripdata_2017*.csv' --quiet\n",
    "!aws s3 sync 's3://nyc-tlc/trip data/' {STAGING_BUCKET}/green --exclude=\"*\" --include='green_tripdata_2018*.csv' \n",
    "\n",
    "print('yellow:')\n",
    "!aws s3 sync 's3://nyc-tlc/trip data/' {STAGING_BUCKET}/yellow --exclude=\"*\" --include='yellow_tripdata_2016*.csv' --quiet\n",
    "!aws s3 sync 's3://nyc-tlc/trip data/' {STAGING_BUCKET}/yellow --exclude=\"*\" --include='yellow_tripdata_2017*.csv' --quiet\n",
    "!aws s3 sync 's3://nyc-tlc/trip data/' {STAGING_BUCKET}/yellow --exclude=\"*\" --include='yellow_tripdata_2018*.csv' \n",
    "\n",
    "!aws s3 ls {STAGING_BUCKET}/ref/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyathena import connect\n",
    "from pyathena.pandas_cursor import PandasCursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_REF_SQL = \"\"\"\n",
    "CREATE EXTERNAL TABLE `taxi_zones`(\n",
    "  `locationid` bigint, \n",
    "  `borough` string, \n",
    "  `zone` string, \n",
    "  `service_zone` string)\n",
    "ROW FORMAT DELIMITED \n",
    "  FIELDS TERMINATED BY ',' \n",
    "STORED AS INPUTFORMAT \n",
    "  'org.apache.hadoop.mapred.TextInputFormat' \n",
    "OUTPUTFORMAT \n",
    "  'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
    "LOCATION\n",
    "  's3://mkamp-aws-tmp/nyc_tmp/ref'\n",
    "TBLPROPERTIES (\n",
    "  'classification'='csv', \n",
    "  'columnsOrdered'='true', \n",
    "  'compressionType'='none', \n",
    "  'typeOfData'='file')\n",
    "\"\"\"\n",
    "\n",
    "CREATE_YELLOW_SQL = \"\"\"\n",
    "CREATE EXTERNAL TABLE `raw_yellow`(\n",
    "  `vendorid` bigint, \n",
    "  `lpep_pickup_datetime` string, \n",
    "  `lpep_dropoff_datetime` string, \n",
    "  `passenger_count` bigint, \n",
    "  `trip_distance` double, \n",
    "  `ratecodeid` bigint, \n",
    "  `store_and_forward_flag` string, \n",
    "  `pu_locationid` bigint, \n",
    "  `do_locationid` bigint, \n",
    "  `payment_type` bigint, \n",
    "  `fare_amount` double, \n",
    "  `extra` double, \n",
    "  `mta_tax` double, \n",
    "  `tip_amount` double, \n",
    "  `tolls_amount` double, \n",
    "  `improvement_surcharge` double, \n",
    "  `total_amount` double)\n",
    "ROW FORMAT DELIMITED \n",
    "  FIELDS TERMINATED BY ',' \n",
    "STORED AS INPUTFORMAT \n",
    "  'org.apache.hadoop.mapred.TextInputFormat' \n",
    "OUTPUTFORMAT \n",
    "  'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
    "LOCATION\n",
    "  's3://mkamp-aws-tmp/nyc_tmp/yellow'\n",
    "TBLPROPERTIES (\n",
    "  'classification'='csv', \n",
    "  'columnsOrdered'='true', \n",
    "  'compressionType'='none', \n",
    "  'skip.header.line.count'='1',\n",
    "  'typeOfData'='file')\n",
    "\"\"\"\n",
    "\n",
    "CREATE_GREEN_SQL = \"\"\"\n",
    "CREATE EXTERNAL TABLE `raw_green`(\n",
    "  `vendorid` bigint, \n",
    "  `lpep_pickup_datetime` string, \n",
    "  `lpep_dropoff_datetime` string, \n",
    "  `store_and_forward_flag` string, \n",
    "  `ratecodeid` bigint, \n",
    "  `pu_locationid` bigint, \n",
    "  `do_locationid` bigint, \n",
    "  `passenger_count` bigint, \n",
    "  `trip_distance` double, \n",
    "  `fare_amount` double, \n",
    "  `extra` double, \n",
    "  `mta_tax` double, \n",
    "  `tip_amount` double, \n",
    "  `tolls_amount` double, \n",
    "  `ehail_fee` string, \n",
    "  `improvement_surcharge` double, \n",
    "  `total_amount` double, \n",
    "  `payment_type` bigint, \n",
    "  `trip_type` bigint)\n",
    "ROW FORMAT DELIMITED \n",
    "  FIELDS TERMINATED BY ',' \n",
    "STORED AS INPUTFORMAT \n",
    "  'org.apache.hadoop.mapred.TextInputFormat' \n",
    "OUTPUTFORMAT \n",
    "  'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
    "LOCATION\n",
    "  's3://mkamp-aws-tmp/nyc_tmp/green'\n",
    "TBLPROPERTIES (\n",
    "  'classification'='csv', \n",
    "  'columnsOrdered'='true', \n",
    "  'compressionType'='none', \n",
    "  'skip.header.line.count'='1',\n",
    "  'typeOfData'='file')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyathena.connection.Connection object at 0x7fa69dc179b0>\n",
      "<pyathena.cursor.Cursor object at 0x7fa69e1c5320>\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. AlreadyExistsException(message:Table taxi_zones already exist)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pyathena/util.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pyathena/cursor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, operation, parameters)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 self.retry_max_delay, self.retry_exponential_base)\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOperationalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_change_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. AlreadyExistsException(message:Table taxi_zones already exist)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "connection = connect(s3_staging_dir='s3://mkamp-fastai/staging/',\n",
    "                 region_name='eu-west-1')\n",
    "print(connection)\n",
    "cursor = connection.cursor()\n",
    "print(cursor)\n",
    "print('ref result:', cursor.execute(CREATE_REF_SQL))\n",
    "print('yellow result:', cursor.execute(CREATE_YELLOW_SQL))\n",
    "print('green result:', cursor.execute(CREATE_GREEN_SQL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "Query timeout",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-ceaf58c4e420>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0myear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpu_dt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2016\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2017\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2018\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \"\"\"\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prepare raw trips sql:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPREPARE_RAW_TRIPS_SQL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pyathena/util.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pyathena/cursor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, operation, parameters)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 self.retry_max_delay, self.retry_exponential_base)\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOperationalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_change_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: Query timeout"
     ]
    }
   ],
   "source": [
    "PREPARE_RAW_TRIPS_SQL = \"\"\"\n",
    "CREATE OR REPLACE VIEW \"raw_trips\" AS\n",
    "WITH \n",
    "  yellow_trips AS (\n",
    "    SELECT\n",
    "      CAST(parse_datetime(lpep_pickup_datetime, 'YYYY-MM-dd HH:mm:ss') AS TIMESTAMP) pu_dt,\n",
    "      CAST(parse_datetime(lpep_dropoff_datetime, 'YYYY-MM-dd HH:mm:ss') AS TIMESTAMP) do_dt,\n",
    "      'yellow' source,\n",
    "      pu_locationid,\n",
    "      do_locationid,\n",
    "      trip_distance,\n",
    "      fare_amount\n",
    "    FROM \n",
    "      raw_yellow),\n",
    "  green_trips AS (\n",
    "    SELECT\n",
    "      CAST(parse_datetime(lpep_pickup_datetime, 'YYYY-MM-dd HH:mm:ss') AS TIMESTAMP) pu_dt,\n",
    "      CAST(parse_datetime(lpep_dropoff_datetime, 'YYYY-MM-dd HH:mm:ss') AS TIMESTAMP) do_dt,\n",
    "      'green' source,\n",
    "      pu_locationid,\n",
    "      do_locationid,\n",
    "      trip_distance,\n",
    "      fare_amount\n",
    "    FROM \n",
    "      raw_green)\n",
    "SELECT * FROM green_trips\n",
    "WHERE\n",
    "  pu_dt >= timestamp '2016-01-01 00:00 UTC' AND\n",
    "  pu_dt <  timestamp '2018-07-01 00:00 UTC' \n",
    "UNION\n",
    "SELECT * FROM yellow_trips\n",
    "WHERE\n",
    "  year(pu_dt) in (2016, 2017, 2018)\n",
    "\"\"\"\n",
    "print('prepare raw trips sql:', cursor.execute(PREPARE_RAW_TRIPS_SQL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE_PREPARED_TRIPS_SQL: <pyathena.cursor.Cursor object at 0x7fa69dbcff98>\n"
     ]
    }
   ],
   "source": [
    "CREATE_PREPARED_TRIPS_SQL = \"\"\"\n",
    "CREATE OR REPLACE VIEW prepared_trips AS\n",
    "SELECT\n",
    "  rt.pu_dt,\n",
    "  rt.do_dt,\n",
    "  coalesce(tz_pu.borough, 'Data Missing') pu_borough,\n",
    "  coalesce(tz_pu.zone, 'Data Missing') pu_zone,\n",
    "  coalesce(tz_do.borough, 'Data Missing') do_borough,\n",
    "  coalesce(tz_do.zone, 'Data Missing') do_zone,\n",
    "  rt.source,\n",
    "  rt.trip_distance,\n",
    "  rt.fare_amount,\n",
    "  CAST((to_unixtime(rt.do_dt) - to_unixtime(rt.pu_dt)) AS INTEGER) trip_duration_s\n",
    "FROM \n",
    "  raw_trips rt\n",
    "  LEFT OUTER JOIN taxi_zones tz_pu ON rt.pu_locationid = tz_pu.locationid\n",
    "  LEFT OUTER JOIN taxi_zones tz_do ON rt.do_locationid = tz_do.locationid\n",
    "\"\"\"\n",
    "print('CREATE_PREPARED_TRIPS_SQL:', cursor.execute(CREATE_PREPARED_TRIPS_SQL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE_PREPARED_TRIPS_AGGREGATED_SQL: <pyathena.cursor.Cursor object at 0x7fa69dbcff98>\n"
     ]
    }
   ],
   "source": [
    "CREATE_PREPARED_TRIPS_AGGREGATED_SQL = \"\"\"\n",
    "CREATE OR REPLACE VIEW prepared_trips_aggregated AS \n",
    "SELECT\n",
    "  date_trunc('hour', pu_dt) pu_dt, \n",
    "  year(pu_dt)  pu_year,\n",
    "  month(pu_dt) pu_month,\n",
    "  day(pu_dt)   pu_day,\n",
    "  hour(pu_dt)  pu_hour,\n",
    "  pu_borough,\n",
    "  pu_zone,\n",
    "  source,\n",
    "  COUNT(*) freq\n",
    "FROM \n",
    "  prepared_trips\n",
    "WHERE \n",
    "  pu_borough != 'Data Missing' AND\n",
    "  pu_borough != 'Data Missing'\n",
    "GROUP BY 1, 2, 3, 4, 5, 6, 7, 8\n",
    "ORDER BY 1 desc\n",
    "\"\"\"\n",
    "print('CREATE_PREPARED_TRIPS_AGGREGATED_SQL:', cursor.execute(CREATE_PREPARED_TRIPS_AGGREGATED_SQL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATERIALIZE AGGREGATE <pyathena.cursor.Cursor object at 0x7fa69e1c5320>\n",
      "CPU times: user 279 ms, sys: 0 ns, total: 279 ms\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SQL = \"\"\"\n",
    "CREATE TABLE prepared_trips_aggregated_materialized \n",
    "WITH (\n",
    "  format='Parquet',\n",
    "  parquet_compression = 'SNAPPY',\n",
    "  external_location='s3://mkamp-aws-tmp/nyc_tmp/prepared/',\n",
    "  partitioned_by = ARRAY['pu_year', 'pu_month']) \n",
    "AS\n",
    "SELECT \n",
    "   pu_dt,\n",
    "   pu_hour,\n",
    "   pu_borough,\n",
    "   pu_zone,\n",
    "   source,\n",
    "   freq,\n",
    "   pu_year,\n",
    "   pu_month\n",
    "FROM \n",
    "  prepared_trips_aggregated\n",
    "ORDER BY 1 desc\n",
    "\"\"\"\n",
    "print('MATERIALIZE AGGREGATE', cursor.execute(SQL))\n",
    "print(cursor.data_scanned_in_bytes/1024**3) # GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                pu_dt               do_dt  source  pu_locationid  \\\n",
      "0 2017-05-16 16:57:32 2017-05-16 17:02:05  yellow            141   \n",
      "1 2017-05-16 16:57:32 2017-05-16 17:08:15  yellow            113   \n",
      "2 2017-05-16 16:57:32 2017-05-16 17:02:17  yellow            236   \n",
      "3 2017-05-16 16:57:33 2017-05-16 17:34:54  yellow            132   \n",
      "4 2017-05-16 16:57:33 2017-05-16 17:00:12  yellow            239   \n",
      "5 2017-05-16 16:57:33 2017-05-16 17:01:17  yellow            262   \n",
      "6 2017-05-16 16:57:33 2017-05-17 16:54:58  yellow            142   \n",
      "7 2017-05-16 16:57:33 2017-05-16 17:25:03  yellow            229   \n",
      "8 2017-05-16 16:57:33 2017-05-16 17:24:27  yellow              4   \n",
      "9 2017-05-16 16:57:33 2017-05-16 17:06:52  yellow            170   \n",
      "\n",
      "   do_locationid  trip_distance  fare_amount  \n",
      "0            263           1.22          5.5  \n",
      "1            114           0.53          7.5  \n",
      "2            237           0.60          5.0  \n",
      "3             95           8.30         32.0  \n",
      "4            238           0.50          4.5  \n",
      "5            263           0.50          4.5  \n",
      "6            143           0.59          5.0  \n",
      "7            230           1.91         17.0  \n",
      "8            231           1.77         16.5  \n",
      "9            137           0.87          7.0  \n",
      "CPU times: user 71.6 ms, sys: 0 ns, total: 71.6 ms\n",
      "Wall time: 3.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cursor = connect(s3_staging_dir='s3://mkamp-fastai/staging/',\n",
    "                 region_name='eu-west-1',\n",
    "                 cursor_class=PandasCursor).cursor()\n",
    "\n",
    "df_raw = cursor.execute(\"SELECT * FROM raw_trips LIMIT 10\").as_pandas()\n",
    "print(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT pu_year, pu_month, sum(freq)/1000000.0 FROM default.prepared_trips_aggregated_materialized \n",
    "GROUP BY 1, 2 \n",
    "ORDER BY 1, 2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
